{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from PIL import Image\n",
    "\n",
    "from layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_path = './input/train-jpg/'\n",
    "test_path = './input/test-jpg/'\n",
    "train = pd.read_csv('./input/train_v2.csv')\n",
    "test = pd.read_csv('./input/sample_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479, 2)\n",
      "(61191, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "NUM_TRAIN = 32000\n",
    "NUM_VAL = train.shape[0]-NUM_TRAIN\n",
    "NUM_TEST = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name         train_0\n",
      "tags          haze primary\n",
      "Name: 0, dtype: object\n",
      "image_name                                  test_0\n",
      "tags          primary clear agriculture road water\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[0])\n",
    "print(test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_5</td>\n",
       "      <td>haze primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_6</td>\n",
       "      <td>agriculture clear cultivation primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_7</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_8</td>\n",
       "      <td>agriculture clear cultivation primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_9</td>\n",
       "      <td>agriculture clear cultivation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                         tags\n",
       "0    train_0                                 haze primary\n",
       "1    train_1              agriculture clear primary water\n",
       "2    train_2                                clear primary\n",
       "3    train_3                                clear primary\n",
       "4    train_4    agriculture clear habitation primary road\n",
       "5    train_5                           haze primary water\n",
       "6    train_6  agriculture clear cultivation primary water\n",
       "7    train_7                                 haze primary\n",
       "8    train_8        agriculture clear cultivation primary\n",
       "9    train_9   agriculture clear cultivation primary road"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['haze', 'primary']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tags'][0].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD\n",
    "Make loop to import all images & store as a numpy array of (3,32,32)'s\n",
    "Save extracted image data somewhere so I don't need to preprocess each time\n",
    "Convert text labels into multi-hot vectors, with vocab as the 17 labels in alphabetical order. 1 = agriculture, 2 = clear, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agriculture': 0,\n",
       " 'artisinal_mine': 1,\n",
       " 'bare_ground': 2,\n",
       " 'blooming': 3,\n",
       " 'blow_down': 4,\n",
       " 'clear': 5,\n",
       " 'cloudy': 6,\n",
       " 'conventional_mine': 7,\n",
       " 'cultivation': 8,\n",
       " 'habitation': 9,\n",
       " 'haze': 10,\n",
       " 'partly_cloudy': 11,\n",
       " 'primary': 12,\n",
       " 'road': 13,\n",
       " 'selective_logging': 14,\n",
       " 'slash_burn': 15,\n",
       " 'water': 16}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [item for i in range(train.shape[0]) for item in train['tags'][i].split()]\n",
    "vocab_ordered = sorted(set(vocab))\n",
    "vocab_dict = {word: index for index, word in enumerate(vocab_ordered)}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_inds = [[vocab_dict[word] for word in row.split()] for row in train['tags']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "labels_words = [set([word for word in row.split()]) for row in train['tags']]\n",
    "labels = mlb.fit_transform(labels_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = np.zeros((100,3,256,256))\n",
    "for i,image_name in enumerate(train['image_name'][:100]):\n",
    "    im = Image.open(train_path + image_name + '.jpg')\n",
    "    im = np.array(im)[:,:,:3]\n",
    "    im = np.reshape(im,(im.shape[2],im.shape[0],im.shape[1]))\n",
    "    train_dataset[i,:,:,:] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3, 256, 256)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "( 0 ,.,.) = \n",
      "  158  143  150  ...   146  153  163\n",
      "  146  153  160  ...   151  164  148\n",
      "  151  165  148  ...   160  146  152\n",
      "      ...         ⋱        ...      \n",
      "  147  156  166  ...   149  160  146\n",
      "  152  161  145  ...   160  141  150\n",
      "  166  147  153  ...   149  156  171\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  148  157  168  ...   147  159  145\n",
      "  150  160  144  ...   161  141  149\n",
      "  166  147  153  ...   149  154  169\n",
      "      ...         ⋱        ...      \n",
      "  148  159  142  ...   167  143  152\n",
      "  160  144  158  ...   146  150  162\n",
      "  146  151  160  ...   145  157  139\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  146  158  140  ...   166  146  151\n",
      "  159  144  158  ...   146  150  164\n",
      "  146  151  164  ...   143  156  137\n",
      "      ...         ⋱        ...      \n",
      "  157  147  149  ...   140  147  153\n",
      "  140  145  153  ...   156  162  151\n",
      "  157  162  149  ...   172  153  157\n",
      "[torch.DoubleTensor of size 3x256x256]\n",
      ", \n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 17]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.from_numpy(train_dataset)\n",
    "our_labels = torch.from_numpy(labels[:100])\n",
    "train_tensor_dataset = torch.utils.data.TensorDataset(train_data, our_labels)\n",
    "print(train_tensor_dataset[0])\n",
    "loader_train = torch.utils.data.DataLoader(train_tensor_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 17])\n"
     ]
    }
   ],
   "source": [
    "simple_model = nn.Sequential(\n",
    "                nn.Conv2d(3, 3, kernel_size=3, stride=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(3),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                Flatten(),\n",
    "                nn.Linear(48387,17)\n",
    "              )\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "simple_model.type(gpu_dtype)\n",
    "\n",
    "#check output dimensions before flattening\n",
    "model_gpu = copy.deepcopy(simple_model).type(gpu_dtype)\n",
    "model_gpu.eval()\n",
    "x = torch.randn(10, 3, 256, 256).type(gpu_dtype)\n",
    "x_var = Variable(x.type(gpu_dtype)) # Construct a PyTorch Variable out of your input data\n",
    "scores = model_gpu(x_var)        # Feed it through the model! \n",
    "print(scores.size())\n",
    "\n",
    "loss_fn = nn.MultiLabelSoftMarginLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(simple_model.parameters(), lr=1e-3, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 5, loss = 6.7969\n",
      "t = 10, loss = 3.0138\n"
     ]
    }
   ],
   "source": [
    "simple_model.train()\n",
    "\n",
    "print_every = 5\n",
    "\n",
    "# Load one batch at a time.\n",
    "for t, (x, y) in enumerate(loader_train):\n",
    "    x_var = Variable(x.type(gpu_dtype))\n",
    "    y_var = Variable(y.type(gpu_dtype))\n",
    "\n",
    "    # This is the forward pass: predict the scores for each class, for each x in the batch.\n",
    "    scores = simple_model(x_var)\n",
    "    \n",
    "    # Use the correct y values and the predicted y values to compute the loss.\n",
    "    loss = loss_fn(scores, y_var)\n",
    "    \n",
    "    if (t + 1) % print_every == 0:\n",
    "        print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "\n",
    "    # Zero out all of the gradients for the variables which the optimizer will update.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # This is the backwards pass: compute the gradient of the loss with respect to each \n",
    "    # parameter of the model.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Actually update the parameters of the model using the gradients computed by the backwards pass.\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
